{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "De-Oldification, Super-Resolution and De-blurring with GANs",
      "provenance": [],
      "collapsed_sections": [
        "ZlklUKOwA6yi",
        "TFXVHbK5DZIn",
        "35IxM4Rz3EhH",
        "XWcTvmEGq9Kq",
        "dEAJeE1e0Ter"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlklUKOwA6yi",
        "colab_type": "text"
      },
      "source": [
        "# DeOldification process \n",
        "based on the FastAI colab found in https://github.com/jantic/DeOldify"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCfE3Lhu9S9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    print('GPU not available.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhCPEoJh9WUv",
        "colab_type": "code",
        "outputId": "ae2c1e4a-d442-4ee8-e1dd-4ade10b76b85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/jantic/DeOldify.git DeOldify\n",
        "%cd DeOldify"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DeOldify'...\n",
            "remote: Enumerating objects: 54, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/54)\u001b[K\rremote: Counting objects:   3% (2/54)\u001b[K\rremote: Counting objects:   5% (3/54)\u001b[K\rremote: Counting objects:   7% (4/54)\u001b[K\rremote: Counting objects:   9% (5/54)\u001b[K\rremote: Counting objects:  11% (6/54)\u001b[K\rremote: Counting objects:  12% (7/54)\u001b[K\rremote: Counting objects:  14% (8/54)\u001b[K\rremote: Counting objects:  16% (9/54)\u001b[K\rremote: Counting objects:  18% (10/54)\u001b[K\rremote: Counting objects:  20% (11/54)\u001b[K\rremote: Counting objects:  22% (12/54)\u001b[K\rremote: Counting objects:  24% (13/54)\u001b[K\rremote: Counting objects:  25% (14/54)\u001b[K\rremote: Counting objects:  27% (15/54)\u001b[K\rremote: Counting objects:  29% (16/54)\u001b[K\rremote: Counting objects:  31% (17/54)\u001b[K\rremote: Counting objects:  33% (18/54)\u001b[K\rremote: Counting objects:  35% (19/54)\u001b[K\rremote: Counting objects:  37% (20/54)\u001b[K\rremote: Counting objects:  38% (21/54)\u001b[K\rremote: Counting objects:  40% (22/54)\u001b[K\rremote: Counting objects:  42% (23/54)\u001b[K\rremote: Counting objects:  44% (24/54)\u001b[K\rremote: Counting objects:  46% (25/54)\u001b[K\rremote: Counting objects:  48% (26/54)\u001b[K\rremote: Counting objects:  50% (27/54)\u001b[K\rremote: Counting objects:  51% (28/54)\u001b[K\rremote: Counting objects:  53% (29/54)\u001b[K\rremote: Counting objects:  55% (30/54)\u001b[K\rremote: Counting objects:  57% (31/54)\u001b[K\rremote: Counting objects:  59% (32/54)\u001b[K\rremote: Counting objects:  61% (33/54)\u001b[K\rremote: Counting objects:  62% (34/54)\u001b[K\rremote: Counting objects:  64% (35/54)\u001b[K\rremote: Counting objects:  66% (36/54)\u001b[K\rremote: Counting objects:  68% (37/54)\u001b[K\rremote: Counting objects:  70% (38/54)\u001b[K\rremote: Counting objects:  72% (39/54)\u001b[K\rremote: Counting objects:  74% (40/54)\u001b[K\rremote: Counting objects:  75% (41/54)\u001b[K\rremote: Counting objects:  77% (42/54)\u001b[K\rremote: Counting objects:  79% (43/54)\u001b[K\rremote: Counting objects:  81% (44/54)\u001b[K\rremote: Counting objects:  83% (45/54)\u001b[K\rremote: Counting objects:  85% (46/54)\u001b[K\rremote: Counting objects:  87% (47/54)\u001b[K\rremote: Counting objects:  88% (48/54)\u001b[K\rremote: Counting objects:  90% (49/54)\u001b[K\rremote: Counting objects:  92% (50/54)\u001b[K\rremote: Counting objects:  94% (51/54)\u001b[K\rremote: Counting objects:  96% (52/54)\u001b[K\rremote: Counting objects:  98% (53/54)\u001b[K\rremote: Counting objects: 100% (54/54)\u001b[K\rremote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 2057 (delta 29), reused 32 (delta 17), pack-reused 2003\u001b[K\n",
            "Receiving objects: 100% (2057/2057), 69.36 MiB | 24.01 MiB/s, done.\n",
            "Resolving deltas: 100% (907/907), done.\n",
            "/content/DeblurGAN/DeOldify\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJXBFwh69dEj",
        "colab_type": "code",
        "outputId": "d23e9eb4-36c3-41ac-e290-acbcd7f886a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install -r colab_requirements.txt\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fastai==1.0.51 in /usr/local/lib/python3.6/dist-packages (from -r colab_requirements.txt (line 1)) (1.0.51)\n",
            "Requirement already satisfied: tensorboardX==1.6 in /usr/local/lib/python3.6/dist-packages (from -r colab_requirements.txt (line 2)) (1.6)\n",
            "Requirement already satisfied: ffmpeg in /usr/local/lib/python3.6/dist-packages (from -r colab_requirements.txt (line 3)) (1.4)\n",
            "Requirement already satisfied: ffmpeg-python==0.1.17 in /usr/local/lib/python3.6/dist-packages (from -r colab_requirements.txt (line 4)) (0.1.17)\n",
            "Requirement already satisfied: youtube-dl>=2019.4.17 in /usr/local/lib/python3.6/dist-packages (from -r colab_requirements.txt (line 5)) (2020.3.24)\n",
            "Requirement already satisfied: jupyterlab in /usr/local/lib/python3.6/dist-packages (from -r colab_requirements.txt (line 6)) (2.1.0)\n",
            "Requirement already satisfied: opencv-python>=3.3.0.10 in /usr/local/lib/python3.6/dist-packages (from -r colab_requirements.txt (line 7)) (4.1.2.30)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from -r colab_requirements.txt (line 8)) (7.0.0)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (3.13)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (2.21.0)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (7.352.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (1.18.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (4.6.3)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (2.7.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (3.2.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (20.3)\n",
            "Requirement already satisfied: spacy>=2.0.18 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (2.2.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (3.6.6)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (0.5.0)\n",
            "Requirement already satisfied: fastprogress>=0.1.19 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (0.2.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (1.0.3)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (1.3.2)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX==1.6->-r colab_requirements.txt (line 2)) (3.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX==1.6->-r colab_requirements.txt (line 2)) (1.12.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from ffmpeg-python==0.1.17->-r colab_requirements.txt (line 4)) (0.16.0)\n",
            "Requirement already satisfied: jinja2>=2.10 in /usr/local/lib/python3.6/dist-packages (from jupyterlab->-r colab_requirements.txt (line 6)) (2.11.1)\n",
            "Requirement already satisfied: notebook>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from jupyterlab->-r colab_requirements.txt (line 6)) (5.2.2)\n",
            "Requirement already satisfied: jupyterlab-server>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from jupyterlab->-r colab_requirements.txt (line 6)) (1.1.1)\n",
            "Requirement already satisfied: tornado!=6.0.0,!=6.0.1,!=6.0.2 in /usr/local/lib/python3.6/dist-packages (from jupyterlab->-r colab_requirements.txt (line 6)) (4.5.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==1.0.51->-r colab_requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==1.0.51->-r colab_requirements.txt (line 1)) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==1.0.51->-r colab_requirements.txt (line 1)) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==1.0.51->-r colab_requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==1.0.51->-r colab_requirements.txt (line 1)) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==1.0.51->-r colab_requirements.txt (line 1)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==1.0.51->-r colab_requirements.txt (line 1)) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==1.0.51->-r colab_requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.51->-r colab_requirements.txt (line 1)) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.51->-r colab_requirements.txt (line 1)) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.51->-r colab_requirements.txt (line 1)) (3.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.51->-r colab_requirements.txt (line 1)) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.51->-r colab_requirements.txt (line 1)) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.51->-r colab_requirements.txt (line 1)) (0.6.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.51->-r colab_requirements.txt (line 1)) (2.0.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.51->-r colab_requirements.txt (line 1)) (1.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.51->-r colab_requirements.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.51->-r colab_requirements.txt (line 1)) (4.38.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.51->-r colab_requirements.txt (line 1)) (46.1.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai==1.0.51->-r colab_requirements.txt (line 1)) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.10->jupyterlab->-r colab_requirements.txt (line 6)) (1.1.1)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab->-r colab_requirements.txt (line 6)) (0.8.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab->-r colab_requirements.txt (line 6)) (5.0.5)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab->-r colab_requirements.txt (line 6)) (4.10.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab->-r colab_requirements.txt (line 6)) (5.3.4)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab->-r colab_requirements.txt (line 6)) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab->-r colab_requirements.txt (line 6)) (4.6.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab->-r colab_requirements.txt (line 6)) (5.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.3.1->jupyterlab->-r colab_requirements.txt (line 6)) (4.3.3)\n",
            "Requirement already satisfied: jsonschema>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from jupyterlab-server>=1.1.0->jupyterlab->-r colab_requirements.txt (line 6)) (3.2.0)\n",
            "Requirement already satisfied: json5 in /usr/local/lib/python3.6/dist-packages (from jupyterlab-server>=1.1.0->jupyterlab->-r colab_requirements.txt (line 6)) (0.9.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->fastai==1.0.51->-r colab_requirements.txt (line 1)) (1.6.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook>=4.3.1->jupyterlab->-r colab_requirements.txt (line 6)) (0.6.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->notebook>=4.3.1->jupyterlab->-r colab_requirements.txt (line 6)) (5.5.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->notebook>=4.3.1->jupyterlab->-r colab_requirements.txt (line 6)) (19.0.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab->-r colab_requirements.txt (line 6)) (2.1.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab->-r colab_requirements.txt (line 6)) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab->-r colab_requirements.txt (line 6)) (0.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab->-r colab_requirements.txt (line 6)) (0.4.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab->-r colab_requirements.txt (line 6)) (1.4.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab->-r colab_requirements.txt (line 6)) (3.1.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.3.1->jupyterlab->-r colab_requirements.txt (line 6)) (0.6.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2.1->notebook>=4.3.1->jupyterlab->-r colab_requirements.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->jupyterlab-server>=1.1.0->jupyterlab->-r colab_requirements.txt (line 6)) (0.16.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->jupyterlab-server>=1.1.0->jupyterlab->-r colab_requirements.txt (line 6)) (19.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->fastai==1.0.51->-r colab_requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab->-r colab_requirements.txt (line 6)) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab->-r colab_requirements.txt (line 6)) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab->-r colab_requirements.txt (line 6)) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab->-r colab_requirements.txt (line 6)) (0.7.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.3.1->jupyterlab->-r colab_requirements.txt (line 6)) (0.5.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook>=4.3.1->jupyterlab->-r colab_requirements.txt (line 6)) (0.1.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRTGgQvX9hz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import fastai\n",
        "from deoldify.visualize import *\n",
        "\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DY8DVNBP9kYH",
        "colab_type": "code",
        "outputId": "a51c5273-ced9-46d7-bbd8-ffa34dc0e5d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "# create a repo to store the models and download the pretrained model (Artistic version)\n",
        "\n",
        "!mkdir 'models'\n",
        "!wget https://www.dropbox.com/s/zkehq1uwahhbc2o/ColorizeArtistic_gen.pth?dl=0 -O ./models/ColorizeArtistic_gen.pth"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-13 13:41:43--  https://www.dropbox.com/s/zkehq1uwahhbc2o/ColorizeArtistic_gen.pth?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1, 2620:100:6021:1::a27d:4101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/zkehq1uwahhbc2o/ColorizeArtistic_gen.pth [following]\n",
            "--2020-04-13 13:41:43--  https://www.dropbox.com/s/raw/zkehq1uwahhbc2o/ColorizeArtistic_gen.pth\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucc2c1badc674b11fe3645dcea64.dl.dropboxusercontent.com/cd/0/inline/A1x7zLMhCtuIK9PGOXXL6spDLCylozLStDSII5L4Qe0HPMrdD8068x7pXOkT6dqqrB16Dt-MqhdZmreYidCjR01fwMrfo0KPgln122mFpdDnpg/file# [following]\n",
            "--2020-04-13 13:41:43--  https://ucc2c1badc674b11fe3645dcea64.dl.dropboxusercontent.com/cd/0/inline/A1x7zLMhCtuIK9PGOXXL6spDLCylozLStDSII5L4Qe0HPMrdD8068x7pXOkT6dqqrB16Dt-MqhdZmreYidCjR01fwMrfo0KPgln122mFpdDnpg/file\n",
            "Resolving ucc2c1badc674b11fe3645dcea64.dl.dropboxusercontent.com (ucc2c1badc674b11fe3645dcea64.dl.dropboxusercontent.com)... 162.125.65.6, 2620:100:6021:6::a27d:4106\n",
            "Connecting to ucc2c1badc674b11fe3645dcea64.dl.dropboxusercontent.com (ucc2c1badc674b11fe3645dcea64.dl.dropboxusercontent.com)|162.125.65.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: /cd/0/inline2/A1y0dei8BPo885cXmCxWvPow2TQ9h-Pi8YhlQCkH_CtCkmgRGD5zqmx4ltslaxZtKDcc7k-F4Qu16C9ECrO0Iv8E9elb370oMTaKGSKvD1Zz8BJcona_CzPBTLrnyjvCdbWs2VV7qyxhDstPh1o56GBkgyAE8StWpcDRJUX8I67MspxheNn4u5mvLSBiB4YigY3xDJKKaNrXKU-1eBPKBAnEEWR8cPO-3rqh_A9iXvQIdvToeejCEo8qWqbBrhpQCEnoNl9tfypbBJ75cTC6ufebWHyMvrzk7-6zUTyjWA8QJrzxB92-Q48Yt7LZn8daLnfHxaWFwcjk3RGin3MnryEz/file [following]\n",
            "--2020-04-13 13:41:44--  https://ucc2c1badc674b11fe3645dcea64.dl.dropboxusercontent.com/cd/0/inline2/A1y0dei8BPo885cXmCxWvPow2TQ9h-Pi8YhlQCkH_CtCkmgRGD5zqmx4ltslaxZtKDcc7k-F4Qu16C9ECrO0Iv8E9elb370oMTaKGSKvD1Zz8BJcona_CzPBTLrnyjvCdbWs2VV7qyxhDstPh1o56GBkgyAE8StWpcDRJUX8I67MspxheNn4u5mvLSBiB4YigY3xDJKKaNrXKU-1eBPKBAnEEWR8cPO-3rqh_A9iXvQIdvToeejCEo8qWqbBrhpQCEnoNl9tfypbBJ75cTC6ufebWHyMvrzk7-6zUTyjWA8QJrzxB92-Q48Yt7LZn8daLnfHxaWFwcjk3RGin3MnryEz/file\n",
            "Reusing existing connection to ucc2c1badc674b11fe3645dcea64.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 255144681 (243M) [application/octet-stream]\n",
            "Saving to: ‘./models/ColorizeArtistic_gen.pth’\n",
            "\n",
            "./models/ColorizeAr 100%[===================>] 243.32M  43.1MB/s    in 5.5s    \n",
            "\n",
            "2020-04-13 13:41:50 (44.5 MB/s) - ‘./models/ColorizeArtistic_gen.pth’ saved [255144681/255144681]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mukMSfz9ljd",
        "colab_type": "code",
        "outputId": "463f8d12-45d9-4558-8eed-6a3a4e0daded",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# download a picture to test the model\n",
        "\n",
        "!wget https://media.githubusercontent.com/media/jantic/DeOldify/master/resource_images/watermark.png -O ./resource_images/watermark.png"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-13 13:41:53--  https://media.githubusercontent.com/media/jantic/DeOldify/master/resource_images/watermark.png\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9210 (9.0K) [image/png]\n",
            "Saving to: ‘./resource_images/watermark.png’\n",
            "\n",
            "\r          ./resourc   0%[                    ]       0  --.-KB/s               \r./resource_images/w 100%[===================>]   8.99K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-04-13 13:41:53 (68.0 MB/s) - ‘./resource_images/watermark.png’ saved [9210/9210]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z96N1GvT9uRh",
        "colab_type": "code",
        "outputId": "3b09bdbd-578d-4194-c87a-493c21bb7dde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        }
      },
      "source": [
        "# I then applied the deoldification to 6 pictures I downloaded to the colab instance \n",
        "# and put in /content/DeOldify/input_images\n",
        "\n",
        "colorizer = get_image_colorizer(artistic=True)\n",
        "for i in range(1,7,1):\n",
        "    colorizer.plot_transformed_image('input_images/photo'+str(i)+'.png', render_factor=38, display_render_factor=True, figsize=(16,16))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/fastai/data_block.py:442: UserWarning: Your training set is empty. If this is by design, pass `ignore_empty=True` to remove this warning.\n",
            "  warn(\"Your training set is empty. If this is by design, pass `ignore_empty=True` to remove this warning.\")\n",
            "/usr/local/lib/python3.6/dist-packages/fastai/data_block.py:445: UserWarning: Your validation set is empty. If this is by design, use `split_none()`\n",
            "                 or pass `ignore_empty=True` when labelling to remove this warning.\n",
            "  or pass `ignore_empty=True` when labelling to remove this warning.\"\"\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-aed903fbebd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcolorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_image_colorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martistic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcolorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_transformed_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input_images/photo'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m38\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_render_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DeOldify/deoldify/visualize.py\u001b[0m in \u001b[0;36mget_image_colorizer\u001b[0;34m(render_factor, artistic)\u001b[0m\n\u001b[1;32m    383\u001b[0m ) -> ModelImageVisualizer:\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0martistic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_artistic_image_colorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrender_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrender_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_stable_image_colorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrender_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrender_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DeOldify/deoldify/visualize.py\u001b[0m in \u001b[0;36mget_artistic_image_colorizer\u001b[0;34m(root_folder, weights_name, results_dir, render_factor)\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0mrender_factor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m35\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m ) -> ModelImageVisualizer:\n\u001b[0;32m--> 408\u001b[0;31m     \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_inference_deep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m     \u001b[0mfiltr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMasterFilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mColorizerFilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrender_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0mvis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelImageVisualizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresults_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DeOldify/deoldify/generators.py\u001b[0m in \u001b[0;36mgen_inference_deep\u001b[0;34m(root_folder, weights_name, arch, nf_factor)\u001b[0m\n\u001b[1;32m     86\u001b[0m     )\n\u001b[1;32m     87\u001b[0m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot_folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, file, device, strict, with_opt, purge, remove_module)\u001b[0m\n\u001b[1;32m    259\u001b[0m              with_opt:bool=None, purge:bool=True, remove_module:bool=False):\n\u001b[1;32m    260\u001b[0m         \u001b[0;34m\"Load model and optimizer state (if `with_opt`) `file` from `self.model_dir` using `device`. `file` can be file-like (file or buffer)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mpurge\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpurge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclear_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mpurge\u001b[0;34m(self, clear_opt)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattrs_pkl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz9KFhPy7a49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The Artistic version of the model gave results that were not really realistic \n",
        "# for example some piece of clothing were washed out, like ty-died which was weird\n",
        "# so I downloaded the Stable version of the pretrained model \n",
        "\n",
        "!wget https://www.dropbox.com/s/mwjep3vyqk5mkjc/ColorizeStable_gen.pth?dl=0 -O ./models/ColorizeStable_gen.pth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLvHEcej66Ss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# once again I applied the model to my pictures which gave much more sound results\n",
        "import fastai\n",
        "from deoldify.visualize import *\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "render_factor=30\n",
        "vis = get_image_colorizer(render_factor=render_factor, artistic=False)\n",
        "for i in range(1,7,1):  \n",
        "  vis.plot_transformed_image('input_images/photo'+str(i)+'.png', render_factor=render_factor, figsize=(30,30))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHmR1EE-xhOM",
        "colab_type": "text"
      },
      "source": [
        "By default, when executing the `plot_transformed_image` function, the results are saved in the result_images folder from the Deoldify repo (each image has the same name as the input image).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFXVHbK5DZIn",
        "colab_type": "text"
      },
      "source": [
        "# Super-resolution process\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oykWgM5Ck5KD",
        "colab_type": "text"
      },
      "source": [
        "Now we have our colorized picture, we can then improve the resolution and increase the sharpness afterwards."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qs0M1t3Jl7eH",
        "colab_type": "text"
      },
      "source": [
        "##SRGAN-tensorflow - DOESN'T WORK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8zsydH0k4SX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/brade31919/SRGAN-tensorflow.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zF1InURrmoOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd SRGAN-tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAinFbJIoESJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://drive.google.com/a/gapp.nthu.edu.tw/uc?id=0BxRIhBA0x8lHNDJFVjJEQnZtcmc -O ./SRGAN_pre-trained"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xtY9TuXoMLQ",
        "colab_type": "text"
      },
      "source": [
        "The URL to download the weight of the pretrained model seems to be broken or the `wget` doesn't work in colab\n",
        " -> moving on to another library with a pretrained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Nzzjko0oY84",
        "colab_type": "text"
      },
      "source": [
        "##image-super-resolution\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1z3n3GcwoLuv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd ..\n",
        "!git clone https://github.com/idealo/image-super-resolution.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcHa_bh5offu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd image-super-resolution\n",
        "!python3 setup.py install"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7mo8L7sou8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir super-res-images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljx8yz2Gojcx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ISR.models import RDN, RRDN\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "model = RDN(weights='noise-cancel' ) #noise-cancel psnr-small psnr-large\n",
        "\n",
        "for i in range(1,7):\n",
        "  img = Image.open('/content/DeOldify/result_images/photo'+str(i)+'.png')\n",
        "  lr_img = np.array(img.convert('RGB'))\n",
        "  #model = RRDN(weights='gans')\n",
        "  sr_img = model.predict(lr_img, by_patch_of_size=256, batch_size=1)\n",
        "  Image.fromarray(sr_img).save('/content/image-super-resolution/super-res-images/photo'+str(i)+'_resed_up.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35IxM4Rz3EhH",
        "colab_type": "text"
      },
      "source": [
        "#Debluring process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWcTvmEGq9Kq",
        "colab_type": "text"
      },
      "source": [
        "##DeblurGAN - CONFUSING RESULTS\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3VVuRyvq8QW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd ..\n",
        "!git clone https://github.com/KupynOrest/DeblurGAN.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39eQJy05rJ7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/DeblurGAN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWb30UN7rNyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install dominate ssim visdom"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYdnUHUdrhuB",
        "colab_type": "text"
      },
      "source": [
        "* The weights of the pre-trained model need to be downloaded from the google drive of the developer of the library and then put in the colab instance in the checkpoints directory.\n",
        "* In `test.py`, line 10,replace\n",
        "`from ssim import SSIM` by `from util.metrics import SSIM` as per https://github.com/KupynOrest/DeblurGAN/issues/20 \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3v_iA89yqb9",
        "colab_type": "code",
        "outputId": "141a6ee9-e85f-4fbc-c089-a917ee9773fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "import os\n",
        "\n",
        "!pip install -q torch torchvision feather-format kornia pyarrow Pillow wandb nbdev fastprogress --upgrade\n",
        "\n",
        "!pip install -q git+https://github.com/fastai/fastcore --upgrade\n",
        "\n",
        "os._exit(00)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 143kB 6.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 63.2MB 144kB/s \n",
            "\u001b[K     |████████████████████████████████| 2.1MB 37.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.4MB 40.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 7.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 460kB 47.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 11.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 42.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 9.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 9.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 8.9MB/s \n",
            "\u001b[?25h  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for graphql-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: isr 2.2.0 has requirement tensorflow==2.0.0, but you'll have tensorflow 2.2.0rc2 which is incompatible.\u001b[0m\n",
            "  Building wheel for fastcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fastai2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLVPMc6XrPVE",
        "colab_type": "code",
        "outputId": "7305e52a-bf31-47b5-dd85-9508bbbec63c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 test.py --dataroot /content/image-super-resolution/super-res-images --model test --dataset_mode single --learn_residual"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------ Options -------------\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 1\n",
            "checkpoints_dir: ./checkpoints\n",
            "dataroot: /content/image-super-resolution/super-res-images\n",
            "dataset_mode: single\n",
            "display_id: 1\n",
            "display_port: 8097\n",
            "display_single_pane_ncols: 0\n",
            "display_winsize: 256\n",
            "fineSize: 256\n",
            "gan_type: wgan-gp\n",
            "gpu_ids: [0]\n",
            "how_many: 5000\n",
            "input_nc: 3\n",
            "isTrain: False\n",
            "learn_residual: True\n",
            "loadSizeX: 640\n",
            "loadSizeY: 360\n",
            "max_dataset_size: inf\n",
            "model: test\n",
            "nThreads: 2\n",
            "n_layers_D: 3\n",
            "name: experiment_name\n",
            "ndf: 64\n",
            "ngf: 64\n",
            "no_dropout: False\n",
            "no_flip: False\n",
            "norm: instance\n",
            "ntest: inf\n",
            "output_nc: 3\n",
            "phase: test\n",
            "resize_or_crop: resize_and_crop\n",
            "results_dir: ./results/\n",
            "serial_batches: False\n",
            "which_direction: AtoB\n",
            "which_epoch: latest\n",
            "which_model_netD: basic\n",
            "which_model_netG: resnet_9blocks\n",
            "-------------- End ----------------\n",
            "Opt.nThreads =  1\n",
            "dataset [SingleImageDataset] was created\n",
            "CustomDatasetDataLoader\n",
            "---------- Networks initialized -------------\n",
            "ResnetGenerator(\n",
            "  (model): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): Dropout(p=0.5, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (11): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): Dropout(p=0.5, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (12): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): Dropout(p=0.5, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (13): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): Dropout(p=0.5, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (14): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): Dropout(p=0.5, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (15): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): Dropout(p=0.5, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (16): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): Dropout(p=0.5, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (17): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): Dropout(p=0.5, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (18): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): Dropout(p=0.5, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (19): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (20): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (21): ReLU(inplace=True)\n",
            "    (22): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (23): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (24): ReLU(inplace=True)\n",
            "    (25): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (26): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (27): Tanh()\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 6067459\n",
            "-----------------------------------------------\n",
            "model [TestModel] was created\n",
            "Setting up a new session...\n",
            "Exception in user code:\n",
            "------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\", line 159, in _new_conn\n",
            "    (self._dns_host, self.port), self.timeout, **extra_kw)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/util/connection.py\", line 80, in create_connection\n",
            "    raise err\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/util/connection.py\", line 70, in create_connection\n",
            "    sock.connect(sa)\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\", line 600, in urlopen\n",
            "    chunked=chunked)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\", line 354, in _make_request\n",
            "    conn.request(method, url, **httplib_request_kw)\n",
            "  File \"/usr/lib/python3.6/http/client.py\", line 1254, in request\n",
            "    self._send_request(method, url, body, headers, encode_chunked)\n",
            "  File \"/usr/lib/python3.6/http/client.py\", line 1300, in _send_request\n",
            "    self.endheaders(body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.6/http/client.py\", line 1249, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.6/http/client.py\", line 1036, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.6/http/client.py\", line 974, in send\n",
            "    self.connect()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\", line 181, in connect\n",
            "    conn = self._new_conn()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\", line 168, in _new_conn\n",
            "    self, \"Failed to establish a new connection: %s\" % e)\n",
            "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fde616cfcc0>: Failed to establish a new connection: [Errno 111] Connection refused\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/requests/adapters.py\", line 449, in send\n",
            "    timeout=timeout\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\", line 638, in urlopen\n",
            "    _stacktrace=sys.exc_info()[2])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/urllib3/util/retry.py\", line 399, in increment\n",
            "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
            "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fde616cfcc0>: Failed to establish a new connection: [Errno 111] Connection refused',))\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/visdom/__init__.py\", line 711, in _send\n",
            "    data=json.dumps(msg),\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/visdom/__init__.py\", line 677, in _handle_post\n",
            "    r = self.session.post(url, data=data)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/requests/sessions.py\", line 581, in post\n",
            "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/requests/sessions.py\", line 533, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/requests/sessions.py\", line 646, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/requests/adapters.py\", line 516, in send\n",
            "    raise ConnectionError(e, request=request)\n",
            "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fde616cfcc0>: Failed to establish a new connection: [Errno 111] Connection refused',))\n",
            "[Errno 99] Cannot assign requested address\n",
            "[Errno 99] Cannot assign requested address\n",
            "[Errno 99] Cannot assign requested address\n",
            "Visdom python client failed to establish socket to get messages from the server. This feature is optional and can be disabled by initializing Visdom with `use_incoming_socket=False`, which will prevent waiting for this request to timeout.\n",
            "process image... ['/content/image-super-resolution/super-res-images/photo1_resed_up.jpg']\n",
            "process image... ['/content/image-super-resolution/super-res-images/photo2_resed_up.jpg']\n",
            "process image... ['/content/image-super-resolution/super-res-images/photo3_resed_up.jpg']\n",
            "process image... ['/content/image-super-resolution/super-res-images/photo4_resed_up.jpg']\n",
            "process image... ['/content/image-super-resolution/super-res-images/photo5_resed_up.jpg']\n",
            "process image... ['/content/image-super-resolution/super-res-images/photo6_resed_up.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9w8YSTs0Nsr",
        "colab_type": "text"
      },
      "source": [
        "The results doesn't make much sense -> switching to another library\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEAJeE1e0Ter",
        "colab_type": "text"
      },
      "source": [
        "##SRN-Deblur\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0qm4n4LzDiu",
        "colab_type": "code",
        "outputId": "73177356-ba46-436f-f34b-a038a2e7cf0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/jiangsutx/SRN-Deblur.git\n",
        "%cd SRN-Deblur"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'SRN-Deblur'...\n",
            "remote: Enumerating objects: 69, done.\u001b[K\n",
            "remote: Total 69 (delta 0), reused 0 (delta 0), pack-reused 69\u001b[K\n",
            "Unpacking objects: 100% (69/69), done.\n",
            "/content/SRN-Deblur\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRdWEAnE0Y5Y",
        "colab_type": "code",
        "outputId": "8b4a0489-4ccd-4c50-e642-b92f92edf9d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "%cd checkpoints\n",
        "!bash download_model.sh\n",
        "!ls color\n",
        "%cd .."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/SRN-Deblur/checkpoints\n",
            "--2020-04-13 14:07:15--  http://www.xtao.website/shared_url/srndeblur_models.zip\n",
            "Resolving www.xtao.website (www.xtao.website)... 167.88.114.232\n",
            "Connecting to www.xtao.website (www.xtao.website)|167.88.114.232|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 81205330 (77M) [application/zip]\n",
            "Saving to: ‘srndeblur_models.zip’\n",
            "\n",
            "srndeblur_models.zi 100%[===================>]  77.44M  1.30MB/s    in 39s     \n",
            "\n",
            "2020-04-13 14:07:55 (1.99 MB/s) - ‘srndeblur_models.zip’ saved [81205330/81205330]\n",
            "\n",
            "Archive:  srndeblur_models.zip\n",
            "   creating: color/\n",
            "  inflating: color/deblur.model-523000.data-00000-of-00001  \n",
            "  inflating: color/deblur.model-523000.index  \n",
            "  inflating: color/deblur.model-523000.meta  \n",
            "   creating: gray/\n",
            "  inflating: gray/deblur.model-523000.data-00000-of-00001  \n",
            "  inflating: gray/deblur.model-523000.index  \n",
            "  inflating: gray/deblur.model-523000.meta  \n",
            "   creating: lstm/\n",
            "  inflating: lstm/deblur.model-523000.data-00000-of-00001  \n",
            "  inflating: lstm/deblur.model-523000.index  \n",
            "  inflating: lstm/deblur.model-523000.meta  \n",
            "deblur.model-523000.data-00000-of-00001  deblur.model-523000.meta\n",
            "deblur.model-523000.index\n",
            "/content/SRN-Deblur\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab9xfHPt1jet",
        "colab_type": "code",
        "outputId": "30efc60c-407d-4f3a-9a19-c37dba102a49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#need scipy version <=1.1.0 to use the imread fonction from this library\n",
        "!pip uninstall scipy -y\n",
        "!pip install scipy==1.1.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling scipy-1.4.1:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/scipy-1.4.1.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/scipy/*\n",
            "Proceed (y/n)? \u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/cli/base_command.py\", line 153, in _main\n",
            "    status = self.run(options, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/uninstall.py\", line 79, in run\n",
            "    auto_confirm=options.yes, verbose=self.verbosity > 0,\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/req/req_install.py\", line 755, in uninstall\n",
            "    uninstalled_pathset.remove(auto_confirm, verbose)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/req/req_uninstall.py\", line 388, in remove\n",
            "    if auto_confirm or self._allowed_to_proceed(verbose):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/req/req_uninstall.py\", line 431, in _allowed_to_proceed\n",
            "    return ask('Proceed (y/n)? ', ('y', 'n')) == 'y'\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/utils/misc.py\", line 245, in ask\n",
            "    response = input(message)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/main.py\", line 47, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/cli/base_command.py\", line 103, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/cli/base_command.py\", line 183, in _main\n",
            "    logger.debug('Exception information:', exc_info=True)\n",
            "  File \"/usr/lib/python3.6/logging/__init__.py\", line 1296, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.6/logging/__init__.py\", line 1444, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.6/logging/__init__.py\", line 1454, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.6/logging/__init__.py\", line 1516, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.6/logging/__init__.py\", line 865, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.6/logging/handlers.py\", line 73, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.6/logging/__init__.py\", line 1072, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.6/logging/__init__.py\", line 994, in emit\n",
            "    msg = self.format(record)\n",
            "  File \"/usr/lib/python3.6/logging/__init__.py\", line 840, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pip/_internal/utils/logging.py\", line 151, in format\n",
            "    formatted = super(IndentingFormatter, self).format(record)\n",
            "  File \"/usr/lib/python3.6/logging/__init__.py\", line 585, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "  File \"/usr/lib/python3.6/logging/__init__.py\", line 535, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.6/traceback.py\", line 104, in print_exception\n",
            "    type(value), value, tb, limit=limit).format(chain=chain):\n",
            "  File \"/usr/lib/python3.6/traceback.py\", line 509, in __init__\n",
            "    capture_locals=capture_locals)\n",
            "  File \"/usr/lib/python3.6/traceback.py\", line 364, in extract\n",
            "    f.line\n",
            "  File \"/usr/lib/python3.6/traceback.py\", line 286, in line\n",
            "    self._line = linecache.getline(self.filename, self.lineno).strip()\n",
            "  File \"/usr/lib/python3.6/linecache.py\", line 16, in getline\n",
            "    lines = getlines(filename, module_globals)\n",
            "  File \"/usr/lib/python3.6/linecache.py\", line 47, in getlines\n",
            "    return updatecache(filename, module_globals)\n",
            "  File \"/usr/lib/python3.6/linecache.py\", line 137, in updatecache\n",
            "    lines = fp.readlines()\n",
            "  File \"/usr/lib/python3.6/codecs.py\", line 318, in decode\n",
            "    def decode(self, input, final=False):\n",
            "KeyboardInterrupt\n",
            "Collecting scipy==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n",
            "\u001b[K     |████████████████████████████████| 31.2MB 102kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.18.2)\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "Successfully installed scipy-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVz7cXTe0gaM",
        "colab_type": "code",
        "outputId": "1c3e3ec6-e5be-4148-a211-47b86e011d96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#tensorflow version is now 2 by default on colab, change it to 1.X\n",
        "%tensorflow_version 1.x\n",
        "!mkdir /content/SRN-Deblur/results\n",
        "!python3 run_model.py --input_path=/content/image-super-resolution/super-res-images --output_path=/content/SRN-Deblur/results --gpu=0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/SRN-Deblur/results’: File exists\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From run_model.py:50: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/SRN-Deblur/models/model.py:270: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0413 14:10:04.352232 140679143237504 module_wrapper.py:139] From /content/SRN-Deblur/models/model.py:270: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/SRN-Deblur/models/model.py:74: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0413 14:10:04.353641 140679143237504 module_wrapper.py:139] From /content/SRN-Deblur/models/model.py:74: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/SRN-Deblur/models/model.py:85: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W0413 14:10:04.354356 140679143237504 module_wrapper.py:139] From /content/SRN-Deblur/models/model.py:85: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0413 14:10:04.362592 140679143237504 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/SRN-Deblur/models/model.py:129: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "W0413 14:10:05.132668 140679143237504 module_wrapper.py:139] From /content/SRN-Deblur/models/model.py:129: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/SRN-Deblur/models/model.py:273: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0413 14:10:05.782754 140679143237504 module_wrapper.py:139] From /content/SRN-Deblur/models/model.py:273: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/SRN-Deblur/models/model.py:273: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0413 14:10:05.783068 140679143237504 module_wrapper.py:139] From /content/SRN-Deblur/models/model.py:273: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/SRN-Deblur/models/model.py:273: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
            "\n",
            "W0413 14:10:05.783330 140679143237504 module_wrapper.py:139] From /content/SRN-Deblur/models/model.py:273: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
            "\n",
            "2020-04-13 14:10:05.789242: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-04-13 14:10:05.789488: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1489100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-04-13 14:10:05.789524: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-04-13 14:10:05.791663: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-04-13 14:10:05.865683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-13 14:10:05.866730: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14892c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-04-13 14:10:05.866764: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-04-13 14:10:05.867024: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-13 14:10:05.867765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-04-13 14:10:05.868104: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-04-13 14:10:05.878646: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-04-13 14:10:05.880416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-04-13 14:10:05.880752: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-04-13 14:10:05.882867: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-04-13 14:10:05.884137: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-04-13 14:10:05.891274: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-13 14:10:05.891416: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-13 14:10:05.892195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-13 14:10:05.892900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-04-13 14:10:05.892988: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-04-13 14:10:05.894488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-04-13 14:10:05.894519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-04-13 14:10:05.894534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-04-13 14:10:05.894692: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-13 14:10:05.895483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-13 14:10:05.896254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From /content/SRN-Deblur/models/model.py:275: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0413 14:10:05.897169 140679143237504 module_wrapper.py:139] From /content/SRN-Deblur/models/model.py:275: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            " [*] Reading checkpoints...\n",
            "INFO:tensorflow:Restoring parameters from ./checkpoints/color/deblur.model-523000\n",
            "I0413 14:10:05.977415 140679143237504 saver.py:1284] Restoring parameters from ./checkpoints/color/deblur.model-523000\n",
            " [*] Reading intermediate checkpoints... Success\n",
            "2020-04-13 14:10:06.992645: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-13 14:10:10.958961: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "Saving results: /content/SRN-Deblur/results/photo1_resed_up.jpg ... 12.361s\n",
            "Saving results: /content/SRN-Deblur/results/photo2_resed_up.jpg ... 2.101s\n",
            "Saving results: /content/SRN-Deblur/results/photo3_resed_up.jpg ... 2.105s\n",
            "Saving results: /content/SRN-Deblur/results/photo4_resed_up.jpg ... 2.096s\n",
            "Saving results: /content/SRN-Deblur/results/photo5_resed_up.jpg ... 2.105s\n",
            "Saving results: /content/SRN-Deblur/results/photo6_resed_up.jpg ... 2.112s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}